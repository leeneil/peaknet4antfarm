{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "``` shell\n",
    "conda create python=2.7 h5py jupyter -p ~/space/envs/peaknet\n",
    "conda install pytorch=0.1.12 torchvision cuda80 -c pytorch\n",
    "conda install tensorboardX\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/reg/neh/home/liponan/space/envs/peaknet/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torchvision\n",
    "import h5py\n",
    "import numpy as np\n",
    "from peaknet import Peaknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from CXI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_cxi( filename, idx, box_size=7 ):\n",
    "    f = h5py.File(filename, 'r')\n",
    "    nPeaks = f[\"entry_1/result_1/nPeaks\"].value\n",
    "    dataset_hits = len(nPeaks)\n",
    "    print('hits: ' + str(dataset_hits))\n",
    "    dataset_peaks = np.sum(nPeaks)\n",
    "    print('peaks: ' + str(dataset_peaks))\n",
    "    img = f[\"entry_1/data_1/data\"][idx,:,:]\n",
    "    mask = f[\"entry_1/data_1/mask\"][idx,:,:]\n",
    "    img = img * (1-mask)\n",
    "    x_label = f['entry_1/result_1/peakXPosRaw'][idx,:]\n",
    "    y_label = f['entry_1/result_1/peakYPosRaw'][idx,:]\n",
    "    f.close()\n",
    "\n",
    "    imgs = np.reshape( img, (8, 185, 4, 194*2) )\n",
    "    imgs = np.transpose( imgs, (0, 2, 1, 3) )\n",
    "    imgs = np.reshape( imgs, (1, 32, 185, 388) )\n",
    "    n, m, h, w = imgs.shape\n",
    "\n",
    "    cls = np.zeros( (nPeaks[idx],) )\n",
    "    s = np.zeros( (nPeaks[idx],) )\n",
    "    r = np.zeros( (nPeaks[idx],) )\n",
    "    c = np.zeros( (nPeaks[idx],) )\n",
    "    ww = np.zeros( (nPeaks[idx],) )\n",
    "    hh = np.zeros( (nPeaks[idx],) )\n",
    "    for u in range(nPeaks[idx]):\n",
    "        my_s = (int(y_label[u])/185)*4 + (int(x_label[u])/388)\n",
    "        my_r = y_label[u] % 185\n",
    "        my_c = x_label[u] % 388\n",
    "        s[u] = my_s\n",
    "        r[u] = my_r\n",
    "        c[u] = my_c\n",
    "        hh[u] = box_size\n",
    "        ww[u] = box_size\n",
    "    labels = (cls, s, r, c, hh, ww)\n",
    "\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits: 1325\n",
      "peaks: 81069\n",
      "('imgs', (1, 32, 185, 388))\n",
      "('labels', 6, 454)\n"
     ]
    }
   ],
   "source": [
    "filename = \"/reg/neh/home/liponan/data/cxic0415/r0091/cxic0415_0091.cxi.backup\"\n",
    "idx=468\n",
    "imgs, labels = imgs, labels = load_from_cxi( filename, idx )\n",
    "print(\"imgs\", imgs.shape)\n",
    "print(\"labels\", len(labels), len(labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init. network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet (\n",
       "  (models): ModuleList (\n",
       "    (0): Sequential (\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (leaky1): LeakyReLU (0.1, inplace)\n",
       "    )\n",
       "    (1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (2): Sequential (\n",
       "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (leaky2): LeakyReLU (0.1, inplace)\n",
       "    )\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (4): Sequential (\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (leaky3): LeakyReLU (0.1, inplace)\n",
       "    )\n",
       "    (5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (6): Sequential (\n",
       "      (conv4): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (leaky4): LeakyReLU (0.1, inplace)\n",
       "    )\n",
       "    (7): Sequential (\n",
       "      (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (leaky5): LeakyReLU (0.1, inplace)\n",
       "    )\n",
       "    (8): Sequential (\n",
       "      (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (leaky6): LeakyReLU (0.1, inplace)\n",
       "    )\n",
       "    (9): Sequential (\n",
       "      (conv7): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (10): RegionLoss (\n",
       "    )\n",
       "  )\n",
       "  (loss): RegionLoss (\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Peaknet()\n",
    "net.loadCfg( \"../pytorch-yolo2/cfg/newpeaksv10-asic.cfg\" )\n",
    "# net.init_model()\n",
    "net.loadWeights( \"../pytorch-yolo2/cfg/newpeaksv10-asic.cfg\", \n",
    "                \"../darknet/backup/newpeaksv10_100.weights\")\n",
    "net.model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = net.predict( imgs, batch_size=32, use_cuda=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
